{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home1/gzy/NucleiSegmentation/High_CCRCC/Train/504x504_252x252/']\n",
      "['/home1/gzy/NucleiSegmentation/High_CCRCC/Valid/504x504_252x252/']\n",
      "[252, 252] [252, 252]\n",
      "\u001b[32m[1221 10:49:20 @parallel.py:293]\u001b[0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n",
      "[252, 252] [252, 252]\n",
      "\u001b[32m[1221 10:49:20 @logger.py:73]\u001b[0m Argv: /home1/gzy/.conda/envs/hovernet/lib/python3.6/site-packages/ipykernel_launcher.py -f /home1/gzy/.local/share/jupyter/runtime/kernel-cb8afe9f-ff22-4517-a71b-4fd8850f9cdc.json\n",
      "['/home1/gzy/NucleiSegmentation/High_CCRCC/Train/504x504_252x252/']\n",
      "['/home1/gzy/NucleiSegmentation/High_CCRCC/Valid/504x504_252x252/']\n",
      "['/home1/gzy/NucleiSegmentation/High_CCRCC/Train/504x504_252x252/']\n",
      "['/home1/gzy/NucleiSegmentation/High_CCRCC/Valid/504x504_252x252/']\n",
      "\u001b[32m[1221 10:49:23 @interface.py:34]\u001b[0m Automatically applying QueueInput on the DataFlow.\n",
      "\u001b[32m[1221 10:49:23 @develop.py:96]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] ModelDescBase._get_inputs() interface will be deprecated after 30 Mar. Use inputs() instead!\n",
      "\u001b[32m[1221 10:49:23 @input_source.py:220]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
      "\u001b[32m[1221 10:49:23 @training.py:114]\u001b[0m Building graph for training tower 0 ...\n",
      "\u001b[32m[1221 10:49:23 @develop.py:96]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] ModelDescBase._build_graph() interface will be deprecated after 30 Mar. Use build_graph() instead!\n",
      "\u001b[32m[1221 10:49:23 @registry.py:121]\u001b[0m b1/conv1 input: [None, 3, 252, 252]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:129]\u001b[0m b1/conv1 output: [None, 64, 250, 250]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:121]\u001b[0m b1/conv2 input: [None, 64, 250, 250]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:129]\u001b[0m b1/conv2 output: [None, 64, 248, 248]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:121]\u001b[0m b1/pool input: [None, 64, 248, 248]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:129]\u001b[0m b1/pool output: [None, 64, 124, 124]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:121]\u001b[0m b1/conv3 input: [None, 3, 128, 128]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:129]\u001b[0m b1/conv3 output: [None, 64, 126, 126]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:121]\u001b[0m b1/conv4 input: [None, 64, 126, 126]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:129]\u001b[0m b1/conv4 output: [None, 64, 124, 124]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:121]\u001b[0m b2/conv1 input: [None, 128, 124, 124]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:129]\u001b[0m b2/conv1 output: [None, 128, 122, 122]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:121]\u001b[0m b2/conv2 input: [None, 128, 122, 122]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:129]\u001b[0m b2/conv2 output: [None, 128, 120, 120]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:121]\u001b[0m b2/pool input: [None, 128, 120, 120]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:129]\u001b[0m b2/pool output: [None, 128, 60, 60]\n",
      "\u001b[32m[1221 10:49:23 @registry.py:121]\u001b[0m b2/conv3 input: [None, 3, 64, 64]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b2/conv3 output: [None, 128, 62, 62]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b2/conv4 input: [None, 128, 62, 62]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b2/conv4 output: [None, 128, 60, 60]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b3/conv1 input: [None, 256, 60, 60]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b3/conv1 output: [None, 256, 58, 58]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b3/conv2 input: [None, 256, 58, 58]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b3/conv2 output: [None, 256, 56, 56]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b3/pool input: [None, 256, 56, 56]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b3/pool output: [None, 256, 28, 28]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b3/conv3 input: [None, 3, 32, 32]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b3/conv3 output: [None, 256, 30, 30]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b3/conv4 input: [None, 256, 30, 30]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b3/conv4 output: [None, 256, 28, 28]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b4/conv1 input: [None, 512, 28, 28]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b4/conv1 output: [None, 512, 26, 26]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b4/conv2 input: [None, 512, 26, 26]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b4/conv2 output: [None, 512, 24, 24]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b4/pool input: [None, 512, 24, 24]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b4/pool output: [None, 512, 12, 12]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b4/conv3 input: [None, 3, 16, 16]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b4/conv3 output: [None, 512, 14, 14]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b4/conv4 input: [None, 512, 14, 14]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b4/conv4 output: [None, 512, 12, 12]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b5/conv1 input: [None, 1024, 12, 12]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b5/conv1 output: [None, 2048, 10, 10]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b5/conv2 input: [None, 2048, 10, 10]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b5/conv2 output: [None, 2048, 8, 8]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b6/up1 input: [None, 2048, 8, 8]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b6/up1 output: [None, 1024, 16, 16]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b6/conv1 input: [None, 1024, 16, 16]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b6/conv1 output: [None, 1024, 14, 14]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b6/conv2 input: [None, 1024, 14, 14]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b6/conv2 output: [None, 1024, 12, 12]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b6/up2 input: [None, 1024, 12, 12]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b6/up2 output: [None, 1024, 16, 16]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b6/up3 input: [None, 1024, 12, 12]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b6/up3 output: [None, 1024, 16, 16]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b6/conv3 input: [None, 2048, 16, 16]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b6/conv3 output: [None, 1024, 16, 16]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b7/up1 input: [None, 1024, 16, 16]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b7/up1 output: [None, 512, 32, 32]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b7/conv1 input: [None, 512, 32, 32]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b7/conv1 output: [None, 512, 30, 30]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b7/conv2 input: [None, 512, 30, 30]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b7/conv2 output: [None, 512, 28, 28]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b7/up2 input: [None, 512, 28, 28]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b7/up2 output: [None, 512, 32, 32]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b7/up3 input: [None, 512, 28, 28]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b7/up3 output: [None, 512, 32, 32]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b7/conv3 input: [None, 1024, 32, 32]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b7/conv3 output: [None, 512, 32, 32]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b8/up1 input: [None, 512, 32, 32]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b8/up1 output: [None, 256, 64, 64]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b8/conv1 input: [None, 256, 64, 64]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b8/conv1 output: [None, 256, 62, 62]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b8/conv2 input: [None, 256, 62, 62]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b8/conv2 output: [None, 256, 60, 60]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b8/up2 input: [None, 256, 60, 60]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:129]\u001b[0m b8/up2 output: [None, 256, 64, 64]\n",
      "\u001b[32m[1221 10:49:24 @registry.py:121]\u001b[0m b8/up3 input: [None, 256, 60, 60]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m b8/up3 output: [None, 256, 64, 64]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m b8/conv3 input: [None, 512, 64, 64]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m b8/conv3 output: [None, 256, 64, 64]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m b9/up1 input: [None, 256, 64, 64]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m b9/up1 output: [None, 128, 128, 128]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m b9/conv1 input: [None, 128, 128, 128]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m b9/conv1 output: [None, 128, 126, 126]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m b9/conv2 input: [None, 128, 126, 126]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m b9/conv2 output: [None, 128, 124, 124]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m b9/up2 input: [None, 128, 124, 124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m b9/up2 output: [None, 128, 128, 128]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m b9/up3 input: [None, 128, 124, 124]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m b9/up3 output: [None, 128, 128, 128]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m b9/conv3 input: [None, 256, 128, 128]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m b9/conv3 output: [None, 128, 128, 128]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m aux_out1/up input: [None, 128, 128, 128]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m aux_out1/up output: [None, 128, 256, 256]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m aux_out1/conv input: [None, 128, 256, 256]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m aux_out1/conv output: [None, 5, 254, 254]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m aux_out2/up input: [None, 256, 64, 64]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m aux_out2/up output: [None, 256, 256, 256]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m aux_out2/conv input: [None, 256, 256, 256]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m aux_out2/conv output: [None, 5, 254, 254]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m aux_out3/up input: [None, 512, 32, 32]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m aux_out3/up output: [None, 512, 256, 256]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m aux_out3/conv input: [None, 512, 256, 256]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m aux_out3/conv output: [None, 5, 254, 254]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m conv_out0 input: [None, 15, 254, 254]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m conv_out0 output: [None, 5, 252, 252]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m conv_out1 input: [None, 5, 254, 254]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m conv_out1 output: [None, 5, 252, 252]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m conv_out2 input: [None, 5, 254, 254]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m conv_out2 output: [None, 5, 252, 252]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:121]\u001b[0m conv_out3 input: [None, 5, 254, 254]\n",
      "\u001b[32m[1221 10:49:25 @registry.py:129]\u001b[0m conv_out3 output: [None, 5, 252, 252]\n",
      "\u001b[32m[1221 10:49:25 @regularize.py:90]\u001b[0m regularize_cost() found 52 variables to regularize.\n",
      "\u001b[32m[1221 10:49:25 @regularize.py:19]\u001b[0m The following tensors will be regularized: b1/conv1/W:0, b1/conv2/W:0, b1/conv3/W:0, b1/conv4/W:0, b2/conv1/W:0, b2/conv2/W:0, b2/conv3/W:0, b2/conv4/W:0, b3/conv1/W:0, b3/conv2/W:0, b3/conv3/W:0, b3/conv4/W:0, b4/conv1/W:0, b4/conv2/W:0, b4/conv3/W:0, b4/conv4/W:0, b5/conv1/W:0, b5/conv2/W:0, b6/up1/W:0, b6/conv1/W:0, b6/conv2/W:0, b6/up2/W:0, b6/up3/W:0, b6/conv3/W:0, b7/up1/W:0, b7/conv1/W:0, b7/conv2/W:0, b7/up2/W:0, b7/up3/W:0, b7/conv3/W:0, b8/up1/W:0, b8/conv1/W:0, b8/conv2/W:0, b8/up2/W:0, b8/up3/W:0, b8/conv3/W:0, b9/up1/W:0, b9/conv1/W:0, b9/conv2/W:0, b9/up2/W:0, b9/up3/W:0, b9/conv3/W:0, aux_out1/up/W:0, aux_out1/conv/W:0, aux_out2/up/W:0, aux_out2/conv/W:0, aux_out3/up/W:0, aux_out3/conv/W:0, conv_out0/W:0, conv_out1/W:0, conv_out2/W:0, conv_out3/W:0\n",
      "\u001b[32m[1221 10:49:26 @develop.py:96]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] get_cost() and self.cost will be deprecated after 30 Mar. Return the cost tensor directly in build_graph() instead!\n",
      "\u001b[32m[1221 10:49:26 @develop.py:96]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] ModelDescBase._get_optimizer() interface will be deprecated after 30 Mar. Use optimizer() instead!\n",
      "\u001b[32m[1221 10:49:29 @model_utils.py:64]\u001b[0m \u001b[36mTrainable Variables: \n",
      "\u001b[0mname                 shape                    dim\n",
      "-------------------  ------------------  --------\n",
      "b1/conv1/W:0         [3, 3, 3, 64]           1728\n",
      "b1/conv1/bn/gamma:0  [64]                      64\n",
      "b1/conv1/bn/beta:0   [64]                      64\n",
      "b1/conv2/W:0         [3, 3, 64, 64]         36864\n",
      "b1/conv2/b:0         [64]                      64\n",
      "b1/conv3/W:0         [3, 3, 3, 64]           1728\n",
      "b1/conv3/bn/gamma:0  [64]                      64\n",
      "b1/conv3/bn/beta:0   [64]                      64\n",
      "b1/conv4/W:0         [3, 3, 64, 64]         36864\n",
      "b1/conv4/b:0         [64]                      64\n",
      "b2/conv1/W:0         [3, 3, 128, 128]      147456\n",
      "b2/conv1/bn/gamma:0  [128]                    128\n",
      "b2/conv1/bn/beta:0   [128]                    128\n",
      "b2/conv2/W:0         [3, 3, 128, 128]      147456\n",
      "b2/conv2/b:0         [128]                    128\n",
      "b2/conv3/W:0         [3, 3, 3, 128]          3456\n",
      "b2/conv3/bn/gamma:0  [128]                    128\n",
      "b2/conv3/bn/beta:0   [128]                    128\n",
      "b2/conv4/W:0         [3, 3, 128, 128]      147456\n",
      "b2/conv4/b:0         [128]                    128\n",
      "b3/conv1/W:0         [3, 3, 256, 256]      589824\n",
      "b3/conv1/bn/gamma:0  [256]                    256\n",
      "b3/conv1/bn/beta:0   [256]                    256\n",
      "b3/conv2/W:0         [3, 3, 256, 256]      589824\n",
      "b3/conv2/b:0         [256]                    256\n",
      "b3/conv3/W:0         [3, 3, 3, 256]          6912\n",
      "b3/conv3/bn/gamma:0  [256]                    256\n",
      "b3/conv3/bn/beta:0   [256]                    256\n",
      "b3/conv4/W:0         [3, 3, 256, 256]      589824\n",
      "b3/conv4/b:0         [256]                    256\n",
      "b4/conv1/W:0         [3, 3, 512, 512]     2359296\n",
      "b4/conv1/bn/gamma:0  [512]                    512\n",
      "b4/conv1/bn/beta:0   [512]                    512\n",
      "b4/conv2/W:0         [3, 3, 512, 512]     2359296\n",
      "b4/conv2/b:0         [512]                    512\n",
      "b4/conv3/W:0         [3, 3, 3, 512]         13824\n",
      "b4/conv3/bn/gamma:0  [512]                    512\n",
      "b4/conv3/bn/beta:0   [512]                    512\n",
      "b4/conv4/W:0         [3, 3, 512, 512]     2359296\n",
      "b4/conv4/b:0         [512]                    512\n",
      "b5/conv1/W:0         [3, 3, 1024, 2048]  18874368\n",
      "b5/conv1/b:0         [2048]                  2048\n",
      "b5/conv2/W:0         [3, 3, 2048, 2048]  37748736\n",
      "b5/conv2/b:0         [2048]                  2048\n",
      "b6/up1/W:0           [2, 2, 1024, 2048]   8388608\n",
      "b6/up1/b:0           [1024]                  1024\n",
      "b6/conv1/W:0         [3, 3, 1024, 1024]   9437184\n",
      "b6/conv1/b:0         [1024]                  1024\n",
      "b6/conv2/W:0         [3, 3, 1024, 1024]   9437184\n",
      "b6/conv2/b:0         [1024]                  1024\n",
      "b6/up2/W:0           [5, 5, 1024, 1024]  26214400\n",
      "b6/up2/b:0           [1024]                  1024\n",
      "b6/up3/W:0           [5, 5, 1024, 1024]  26214400\n",
      "b6/up3/b:0           [1024]                  1024\n",
      "b6/conv3/W:0         [1, 1, 2048, 1024]   2097152\n",
      "b6/conv3/b:0         [1024]                  1024\n",
      "b7/up1/W:0           [2, 2, 512, 1024]    2097152\n",
      "b7/up1/b:0           [512]                    512\n",
      "b7/conv1/W:0         [3, 3, 512, 512]     2359296\n",
      "b7/conv1/b:0         [512]                    512\n",
      "b7/conv2/W:0         [3, 3, 512, 512]     2359296\n",
      "b7/conv2/b:0         [512]                    512\n",
      "b7/up2/W:0           [5, 5, 512, 512]     6553600\n",
      "b7/up2/b:0           [512]                    512\n",
      "b7/up3/W:0           [5, 5, 512, 512]     6553600\n",
      "b7/up3/b:0           [512]                    512\n",
      "b7/conv3/W:0         [1, 1, 1024, 512]     524288\n",
      "b7/conv3/b:0         [512]                    512\n",
      "b8/up1/W:0           [2, 2, 256, 512]      524288\n",
      "b8/up1/b:0           [256]                    256\n",
      "b8/conv1/W:0         [3, 3, 256, 256]      589824\n",
      "b8/conv1/b:0         [256]                    256\n",
      "b8/conv2/W:0         [3, 3, 256, 256]      589824\n",
      "b8/conv2/b:0         [256]                    256\n",
      "b8/up2/W:0           [5, 5, 256, 256]     1638400\n",
      "b8/up2/b:0           [256]                    256\n",
      "b8/up3/W:0           [5, 5, 256, 256]     1638400\n",
      "b8/up3/b:0           [256]                    256\n",
      "b8/conv3/W:0         [1, 1, 512, 256]      131072\n",
      "b8/conv3/b:0         [256]                    256\n",
      "b9/up1/W:0           [2, 2, 128, 256]      131072\n",
      "b9/up1/b:0           [128]                    128\n",
      "b9/conv1/W:0         [3, 3, 128, 128]      147456\n",
      "b9/conv1/b:0         [128]                    128\n",
      "b9/conv2/W:0         [3, 3, 128, 128]      147456\n",
      "b9/conv2/b:0         [128]                    128\n",
      "b9/up2/W:0           [5, 5, 128, 128]      409600\n",
      "b9/up2/b:0           [128]                    128\n",
      "b9/up3/W:0           [5, 5, 128, 128]      409600\n",
      "b9/up3/b:0           [128]                    128\n",
      "b9/conv3/W:0         [1, 1, 256, 128]       32768\n",
      "b9/conv3/b:0         [128]                    128\n",
      "aux_out1/up/W:0      [2, 2, 128, 128]       65536\n",
      "aux_out1/up/b:0      [128]                    128\n",
      "aux_out1/conv/W:0    [3, 3, 128, 5]          5760\n",
      "aux_out1/conv/b:0    [5]                        5\n",
      "aux_out2/up/W:0      [4, 4, 256, 256]     1048576\n",
      "aux_out2/up/b:0      [256]                    256\n",
      "aux_out2/conv/W:0    [3, 3, 256, 5]         11520\n",
      "aux_out2/conv/b:0    [5]                        5\n",
      "aux_out3/up/W:0      [8, 8, 512, 512]    16777216\n",
      "aux_out3/up/b:0      [512]                    512\n",
      "aux_out3/conv/W:0    [3, 3, 512, 5]         23040\n",
      "aux_out3/conv/b:0    [5]                        5\n",
      "conv_out0/W:0        [3, 3, 15, 5]            675\n",
      "conv_out0/b:0        [5]                        5\n",
      "conv_out1/W:0        [3, 3, 5, 5]             225\n",
      "conv_out1/b:0        [5]                        5\n",
      "conv_out2/W:0        [3, 3, 5, 5]             225\n",
      "conv_out2/b:0        [5]                        5\n",
      "conv_out3/W:0        [3, 3, 5, 5]             225\n",
      "conv_out3/b:0        [5]                        5\u001b[36m\n",
      "Total #vars=112, #params=192595433, size=734.69MB\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 10:49:29 @base.py:209]\u001b[0m Setup callbacks graph ...\n",
      "\u001b[32m[1221 10:49:29 @input_source.py:220]\u001b[0m Setting up the queue 'DataParallelInferenceRunner/QueueInput/input_queue' for CPU prefetching ...\n",
      "\u001b[32m[1221 10:49:29 @inference_runner.py:238]\u001b[0m [InferenceRunner] Building tower 'InferenceTower0' on device /gpu:0 ...\n",
      "\u001b[32m[1221 10:49:29 @develop.py:96]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [Deprecated] ModelDescBase._build_graph() interface will be deprecated after 30 Mar. Use build_graph() instead!\n",
      "\u001b[32m[1221 10:49:30 @summary.py:38]\u001b[0m Maintain moving average summary of 6 tensors in collection MOVING_SUMMARY_OPS.\n",
      "\u001b[32m[1221 10:49:30 @summary.py:75]\u001b[0m Summarizing collection 'summaries' of size 64.\n",
      "\u001b[32m[1221 10:49:30 @graph.py:91]\u001b[0m Applying collection UPDATE_OPS of 16 ops.\n",
      "\u001b[32m[1221 10:49:31 @base.py:227]\u001b[0m Creating the session ...\n",
      "\u001b[32m[1221 10:49:43 @base.py:233]\u001b[0m Initializing the session ...\n",
      "\u001b[32m[1221 10:49:43 @base.py:240]\u001b[0m Graph Finalized.\n",
      "\u001b[32m[1221 10:49:43 @concurrency.py:37]\u001b[0m Starting EnqueueThread QueueInput/input_queue ...\n",
      "\u001b[32m[1221 10:49:44 @concurrency.py:37]\u001b[0m Starting EnqueueThread DataParallelInferenceRunner/QueueInput/input_queue ...\n",
      "\u001b[32m[1221 10:49:44 @inference_runner.py:101]\u001b[0m [InferenceRunner] Will eval 57 iterations\n",
      "\u001b[32m[1221 10:49:44 @base.py:272]\u001b[0m Start Epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[08:05<00:00, 1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 10:57:50 @base.py:282]\u001b[0m Epoch 1 (global_step 787) finished, time:8 minutes 5 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 10:57:55 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-787.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:35<00:00, 1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 10:58:43 @saver.py:159]\u001b[0m Model at global_step=787 with maximum valid_dice=0.8337 saved.\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m aux_loss_dw: 1\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m l2_wd_loss: 0.050027\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m loss-bce-0: 0.20188\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m loss-bce-1: 0.26497\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m loss-bce-2: 0.22505\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m loss-bce-3: 0.21495\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m overall_cost: 0.95688\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m valid_acc: 0.97085\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m valid_dice: 0.8337\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.0036688\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.67245\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.048859\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.0010501\n",
      "\u001b[32m[1221 10:58:43 @monitor.py:459]\u001b[0m valid_mean_dice: 0.18151\n",
      "\u001b[32m[1221 10:58:43 @group.py:48]\u001b[0m Callbacks took 53.048 sec in total. DataParallelInferenceRunner: 45.9 seconds\n",
      "\u001b[32m[1221 10:58:43 @base.py:272]\u001b[0m Start Epoch 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:31<00:00, 1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:06:15 @base.py:282]\u001b[0m Epoch 2 (global_step 1574) finished, time:7 minutes 31 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:06:18 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-1574.\n",
      "\u001b[32m[1221 11:06:18 @param.py:158]\u001b[0m [HyperParamSetter] At global_step=1574, aux_loss_dw is set to 0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:18<00:00, 3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:06:48 @saver.py:159]\u001b[0m Model at global_step=1574 with maximum valid_dice=0.8467 saved.\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m aux_loss_dw: 1\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m l2_wd_loss: 0.043624\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m loss-bce-0: 0.17926\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m loss-bce-1: 0.20025\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m loss-bce-2: 0.19276\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m loss-bce-3: 0.1914\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m overall_cost: 0.80729\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m valid_acc: 0.97411\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m valid_dice: 0.8467\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.48093\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.69709\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.046892\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.012924\n",
      "\u001b[32m[1221 11:06:48 @monitor.py:459]\u001b[0m valid_mean_dice: 0.30946\n",
      "\u001b[32m[1221 11:06:48 @group.py:48]\u001b[0m Callbacks took 33.869 sec in total. DataParallelInferenceRunner: 28.8 seconds\n",
      "\u001b[32m[1221 11:06:48 @base.py:272]\u001b[0m Start Epoch 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:31<00:00, 1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:14:20 @base.py:282]\u001b[0m Epoch 3 (global_step 2361) finished, time:7 minutes 31 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:14:23 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-2361.\n",
      "\u001b[32m[1221 11:14:23 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=2361, aux_loss_dw changes from 0.500000 to 0.333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:17<00:00, 3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m aux_loss_dw: 0.5\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m l2_wd_loss: 0.038922\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m loss-bce-0: 0.15\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m loss-bce-1: 0.083907\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m loss-bce-2: 0.083985\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m loss-bce-3: 0.083717\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m overall_cost: 0.44053\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m valid_acc: 0.97379\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m valid_dice: 0.84192\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.49075\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.70552\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.056672\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.0034383\n",
      "\u001b[32m[1221 11:14:52 @monitor.py:459]\u001b[0m valid_mean_dice: 0.3141\n",
      "\u001b[32m[1221 11:14:52 @group.py:48]\u001b[0m Callbacks took 32.731 sec in total. DataParallelInferenceRunner: 29.8 seconds\n",
      "\u001b[32m[1221 11:14:52 @base.py:272]\u001b[0m Start Epoch 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:31<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:22:23 @base.py:282]\u001b[0m Epoch 4 (global_step 3148) finished, time:7 minutes 31 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:22:26 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-3148.\n",
      "\u001b[32m[1221 11:22:26 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=3148, aux_loss_dw changes from 0.333333 to 0.250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:17<00:00, 3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m aux_loss_dw: 0.33333\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m l2_wd_loss: 0.035071\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m loss-bce-0: 0.15341\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m loss-bce-1: 0.055684\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m loss-bce-2: 0.057566\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m loss-bce-3: 0.057566\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m overall_cost: 0.3593\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m valid_acc: 0.97428\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m valid_dice: 0.84614\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.47246\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.72493\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.2029\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.045034\n",
      "\u001b[32m[1221 11:22:54 @monitor.py:459]\u001b[0m valid_mean_dice: 0.36133\n",
      "\u001b[32m[1221 11:22:54 @group.py:48]\u001b[0m Callbacks took 30.835 sec in total. DataParallelInferenceRunner: 27.9 seconds\n",
      "\u001b[32m[1221 11:22:54 @base.py:272]\u001b[0m Start Epoch 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:30<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:30:25 @base.py:282]\u001b[0m Epoch 5 (global_step 3935) finished, time:7 minutes 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:30:28 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-3935.\n",
      "\u001b[32m[1221 11:30:28 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=3935, aux_loss_dw changes from 0.250000 to 0.200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:17<00:00, 3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:30:56 @saver.py:159]\u001b[0m Model at global_step=3935 with maximum valid_dice=0.8528 saved.\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m aux_loss_dw: 0.25\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m l2_wd_loss: 0.031872\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m loss-bce-0: 0.142\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m loss-bce-1: 0.039194\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m loss-bce-2: 0.040874\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m loss-bce-3: 0.040684\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m overall_cost: 0.29462\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m valid_acc: 0.97427\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m valid_dice: 0.8528\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.49716\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.73338\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.36001\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.11586\n",
      "\u001b[32m[1221 11:30:56 @monitor.py:459]\u001b[0m valid_mean_dice: 0.4266\n",
      "\u001b[32m[1221 11:30:56 @group.py:48]\u001b[0m Callbacks took 31.132 sec in total. DataParallelInferenceRunner: 27.2 seconds\n",
      "\u001b[32m[1221 11:30:56 @base.py:272]\u001b[0m Start Epoch 6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:30<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:38:26 @base.py:282]\u001b[0m Epoch 6 (global_step 4722) finished, time:7 minutes 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:38:29 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-4722.\n",
      "\u001b[32m[1221 11:38:29 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=4722, aux_loss_dw changes from 0.200000 to 0.166667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m aux_loss_dw: 0.2\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m l2_wd_loss: 0.029175\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m loss-bce-0: 0.13727\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m loss-bce-1: 0.030593\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m loss-bce-2: 0.031747\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m loss-bce-3: 0.031895\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m overall_cost: 0.26068\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m valid_acc: 0.97401\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m valid_dice: 0.8463\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.40558\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.72158\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.39655\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.27607\n",
      "\u001b[32m[1221 11:38:55 @monitor.py:459]\u001b[0m valid_mean_dice: 0.44994\n",
      "\u001b[32m[1221 11:38:55 @group.py:48]\u001b[0m Callbacks took 29.206 sec in total. DataParallelInferenceRunner: 26.4 seconds\n",
      "\u001b[32m[1221 11:38:55 @base.py:272]\u001b[0m Start Epoch 7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:30<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:46:26 @base.py:282]\u001b[0m Epoch 7 (global_step 5509) finished, time:7 minutes 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:46:29 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-5509.\n",
      "\u001b[32m[1221 11:46:29 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=5509, aux_loss_dw changes from 0.166667 to 0.142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m aux_loss_dw: 0.16667\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m l2_wd_loss: 0.026952\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m loss-bce-0: 0.1359\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m loss-bce-1: 0.025722\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m loss-bce-2: 0.026573\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m loss-bce-3: 0.026915\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m overall_cost: 0.24206\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m valid_acc: 0.97391\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m valid_dice: 0.84552\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.48007\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.7163\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.41122\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.36255\n",
      "\u001b[32m[1221 11:46:55 @monitor.py:459]\u001b[0m valid_mean_dice: 0.49253\n",
      "\u001b[32m[1221 11:46:55 @group.py:48]\u001b[0m Callbacks took 29.404 sec in total. DataParallelInferenceRunner: 26.7 seconds\n",
      "\u001b[32m[1221 11:46:55 @base.py:272]\u001b[0m Start Epoch 8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:30<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:54:25 @base.py:282]\u001b[0m Epoch 8 (global_step 6296) finished, time:7 minutes 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:54:28 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-6296.\n",
      "\u001b[32m[1221 11:54:28 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=6296, aux_loss_dw changes from 0.142857 to 0.125000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m aux_loss_dw: 0.14286\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m l2_wd_loss: 0.025079\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m loss-bce-0: 0.12432\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m loss-bce-1: 0.020376\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m loss-bce-2: 0.021256\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m loss-bce-3: 0.021213\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m overall_cost: 0.21224\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m valid_acc: 0.97451\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m valid_dice: 0.85133\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.51441\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.73609\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.29605\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.63291\n",
      "\u001b[32m[1221 11:54:54 @monitor.py:459]\u001b[0m valid_mean_dice: 0.54487\n",
      "\u001b[32m[1221 11:54:54 @group.py:48]\u001b[0m Callbacks took 28.775 sec in total. DataParallelInferenceRunner: 26 seconds\n",
      "\u001b[32m[1221 11:54:54 @base.py:272]\u001b[0m Start Epoch 9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:30<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:02:24 @base.py:282]\u001b[0m Epoch 9 (global_step 7083) finished, time:7 minutes 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:02:27 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-7083.\n",
      "\u001b[32m[1221 12:02:27 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=7083, aux_loss_dw changes from 0.125000 to 0.111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:02:55 @saver.py:159]\u001b[0m Model at global_step=7083 with maximum valid_dice=0.85556 saved.\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m aux_loss_dw: 0.125\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m l2_wd_loss: 0.02343\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m loss-bce-0: 0.12394\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m loss-bce-1: 0.018196\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m loss-bce-2: 0.019046\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m loss-bce-3: 0.019053\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m overall_cost: 0.20366\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m valid_acc: 0.97511\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m valid_dice: 0.85556\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.58143\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.73645\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.31567\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.66766\n",
      "\u001b[32m[1221 12:02:55 @monitor.py:459]\u001b[0m valid_mean_dice: 0.5753\n",
      "\u001b[32m[1221 12:02:55 @group.py:48]\u001b[0m Callbacks took 31.114 sec in total. DataParallelInferenceRunner: 27.1 seconds\n",
      "\u001b[32m[1221 12:02:55 @base.py:272]\u001b[0m Start Epoch 10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:10:25 @base.py:282]\u001b[0m Epoch 10 (global_step 7870) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:10:28 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-7870.\n",
      "\u001b[32m[1221 12:10:28 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=7870, aux_loss_dw changes from 0.111111 to 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:10:56 @saver.py:159]\u001b[0m Model at global_step=7870 with maximum valid_dice=0.85726 saved.\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m aux_loss_dw: 0.11111\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m l2_wd_loss: 0.022099\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m loss-bce-0: 0.12196\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m loss-bce-1: 0.015321\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m loss-bce-2: 0.016308\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m loss-bce-3: 0.01636\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m overall_cost: 0.19205\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m valid_acc: 0.97574\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m valid_dice: 0.85726\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.53073\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.73009\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.36072\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.68115\n",
      "\u001b[32m[1221 12:10:56 @monitor.py:459]\u001b[0m valid_mean_dice: 0.57567\n",
      "\u001b[32m[1221 12:10:56 @group.py:48]\u001b[0m Callbacks took 30.270 sec in total. DataParallelInferenceRunner: 26.4 seconds\n",
      "\u001b[32m[1221 12:10:56 @base.py:272]\u001b[0m Start Epoch 11 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:18:25 @base.py:282]\u001b[0m Epoch 11 (global_step 8657) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:18:28 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-8657.\n",
      "\u001b[32m[1221 12:18:28 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=8657, aux_loss_dw changes from 0.100000 to 0.090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m aux_loss_dw: 0.1\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m l2_wd_loss: 0.020894\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m loss-bce-0: 0.12225\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m loss-bce-1: 0.013646\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m loss-bce-2: 0.014711\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m loss-bce-3: 0.01483\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m overall_cost: 0.18633\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m valid_acc: 0.97492\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m valid_dice: 0.84775\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.50575\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.73739\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.39621\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.68468\n",
      "\u001b[32m[1221 12:18:54 @monitor.py:459]\u001b[0m valid_mean_dice: 0.58101\n",
      "\u001b[32m[1221 12:18:54 @group.py:48]\u001b[0m Callbacks took 29.543 sec in total. DataParallelInferenceRunner: 26.5 seconds\n",
      "\u001b[32m[1221 12:18:54 @base.py:272]\u001b[0m Start Epoch 12 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:26:24 @base.py:282]\u001b[0m Epoch 12 (global_step 9444) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:26:27 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-9444.\n",
      "\u001b[32m[1221 12:26:27 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=9444, aux_loss_dw changes from 0.090909 to 0.083333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:26:56 @saver.py:159]\u001b[0m Model at global_step=9444 with maximum valid_dice=0.86029 saved.\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m aux_loss_dw: 0.090909\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m l2_wd_loss: 0.019883\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m loss-bce-0: 0.1223\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m loss-bce-1: 0.012371\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m loss-bce-2: 0.013536\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m loss-bce-3: 0.013777\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m overall_cost: 0.18187\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m valid_acc: 0.97547\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m valid_dice: 0.86029\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.6119\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.73764\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.4569\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.67701\n",
      "\u001b[32m[1221 12:26:56 @monitor.py:459]\u001b[0m valid_mean_dice: 0.62086\n",
      "\u001b[32m[1221 12:26:56 @group.py:48]\u001b[0m Callbacks took 31.476 sec in total. DataParallelInferenceRunner: 27.6 seconds\n",
      "\u001b[32m[1221 12:26:56 @base.py:272]\u001b[0m Start Epoch 13 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:30<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:34:26 @base.py:282]\u001b[0m Epoch 13 (global_step 10231) finished, time:7 minutes 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:34:28 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-10231.\n",
      "\u001b[32m[1221 12:34:28 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=10231, aux_loss_dw changes from 0.083333 to 0.076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:17<00:00, 3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m aux_loss_dw: 0.083333\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m l2_wd_loss: 0.019002\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m loss-bce-0: 0.1151\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m loss-bce-1: 0.010558\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m loss-bce-2: 0.011537\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m loss-bce-3: 0.011849\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m overall_cost: 0.16804\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m valid_acc: 0.97563\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m valid_dice: 0.85823\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.57194\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.74996\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.43095\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.67265\n",
      "\u001b[32m[1221 12:34:56 @monitor.py:459]\u001b[0m valid_mean_dice: 0.60638\n",
      "\u001b[32m[1221 12:34:56 @group.py:48]\u001b[0m Callbacks took 30.336 sec in total. DataParallelInferenceRunner: 27.7 seconds\n",
      "\u001b[32m[1221 12:34:56 @base.py:272]\u001b[0m Start Epoch 14 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:42:26 @base.py:282]\u001b[0m Epoch 14 (global_step 11018) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:42:29 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-11018.\n",
      "\u001b[32m[1221 12:42:29 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=11018, aux_loss_dw changes from 0.076923 to 0.071429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m aux_loss_dw: 0.076923\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m l2_wd_loss: 0.018262\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m loss-bce-0: 0.11566\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m loss-bce-1: 0.0097531\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m loss-bce-2: 0.01059\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m loss-bce-3: 0.010915\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m overall_cost: 0.16518\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m valid_acc: 0.9757\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m valid_dice: 0.8551\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.54981\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.74291\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.45718\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.6726\n",
      "\u001b[32m[1221 12:42:56 @monitor.py:459]\u001b[0m valid_mean_dice: 0.60563\n",
      "\u001b[32m[1221 12:42:56 @group.py:48]\u001b[0m Callbacks took 30.020 sec in total. DataParallelInferenceRunner: 27.4 seconds\n",
      "\u001b[32m[1221 12:42:56 @base.py:272]\u001b[0m Start Epoch 15 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:50:26 @base.py:282]\u001b[0m Epoch 15 (global_step 11805) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:50:29 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-11805.\n",
      "\u001b[32m[1221 12:50:29 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=11805, aux_loss_dw changes from 0.071429 to 0.066667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m aux_loss_dw: 0.071429\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m l2_wd_loss: 0.017546\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m loss-bce-0: 0.12773\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m loss-bce-1: 0.0099143\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m loss-bce-2: 0.010836\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m loss-bce-3: 0.011138\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m overall_cost: 0.17716\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m valid_acc: 0.97507\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m valid_dice: 0.85212\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.59199\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.71697\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.40696\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.69272\n",
      "\u001b[32m[1221 12:50:55 @monitor.py:459]\u001b[0m valid_mean_dice: 0.60216\n",
      "\u001b[32m[1221 12:50:55 @group.py:48]\u001b[0m Callbacks took 29.182 sec in total. DataParallelInferenceRunner: 26 seconds\n",
      "\u001b[32m[1221 12:50:55 @base.py:272]\u001b[0m Start Epoch 16 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:58:24 @base.py:282]\u001b[0m Epoch 16 (global_step 12592) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:58:27 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-12592.\n",
      "\u001b[32m[1221 12:58:27 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=12592, aux_loss_dw changes from 0.066667 to 0.062500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m aux_loss_dw: 0.066667\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m l2_wd_loss: 0.016964\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m loss-bce-0: 0.11878\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m loss-bce-1: 0.0086534\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m loss-bce-2: 0.0091971\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m loss-bce-3: 0.0097302\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m overall_cost: 0.16333\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m valid_acc: 0.97375\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m valid_dice: 0.85424\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.58751\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.74818\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.44024\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.68209\n",
      "\u001b[32m[1221 12:58:55 @monitor.py:459]\u001b[0m valid_mean_dice: 0.6145\n",
      "\u001b[32m[1221 12:58:55 @group.py:48]\u001b[0m Callbacks took 30.408 sec in total. DataParallelInferenceRunner: 27.5 seconds\n",
      "\u001b[32m[1221 12:58:55 @base.py:272]\u001b[0m Start Epoch 17 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:06:25 @base.py:282]\u001b[0m Epoch 17 (global_step 13379) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:06:28 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-13379.\n",
      "\u001b[32m[1221 13:06:28 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=13379, aux_loss_dw changes from 0.062500 to 0.058824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m aux_loss_dw: 0.0625\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m l2_wd_loss: 0.016519\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m loss-bce-0: 0.11318\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m loss-bce-1: 0.0077353\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m loss-bce-2: 0.0083566\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m loss-bce-3: 0.0088389\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m overall_cost: 0.15463\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m valid_acc: 0.97574\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m valid_dice: 0.85798\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.57716\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.74319\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.46128\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.69933\n",
      "\u001b[32m[1221 13:06:53 @monitor.py:459]\u001b[0m valid_mean_dice: 0.62024\n",
      "\u001b[32m[1221 13:06:53 @group.py:48]\u001b[0m Callbacks took 28.533 sec in total. DataParallelInferenceRunner: 25.3 seconds\n",
      "\u001b[32m[1221 13:06:53 @base.py:272]\u001b[0m Start Epoch 18 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:14:23 @base.py:282]\u001b[0m Epoch 18 (global_step 14166) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:14:25 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-14166.\n",
      "\u001b[32m[1221 13:14:25 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=14166, aux_loss_dw changes from 0.058824 to 0.055556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:14:51 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m aux_loss_dw: 0.058824\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m l2_wd_loss: 0.016092\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m loss-bce-0: 0.11807\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m loss-bce-1: 0.0075837\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m loss-bce-2: 0.0080142\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m loss-bce-3: 0.0085253\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m overall_cost: 0.15829\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m valid_acc: 0.97483\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m valid_dice: 0.84477\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.5401\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.73536\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.44167\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.69718\n",
      "\u001b[32m[1221 13:14:52 @monitor.py:459]\u001b[0m valid_mean_dice: 0.60358\n",
      "\u001b[32m[1221 13:14:52 @group.py:48]\u001b[0m Callbacks took 28.835 sec in total. DataParallelInferenceRunner: 26.1 seconds\n",
      "\u001b[32m[1221 13:14:52 @base.py:272]\u001b[0m Start Epoch 19 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:22:21 @base.py:282]\u001b[0m Epoch 19 (global_step 14953) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:22:24 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-14953.\n",
      "\u001b[32m[1221 13:22:24 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=14953, aux_loss_dw changes from 0.055556 to 0.052632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m aux_loss_dw: 0.055556\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m l2_wd_loss: 0.015742\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m loss-bce-0: 0.12473\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m loss-bce-1: 0.0075062\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m loss-bce-2: 0.0076872\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m loss-bce-3: 0.008369\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m overall_cost: 0.16403\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m valid_acc: 0.97489\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m valid_dice: 0.84725\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.55778\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.74486\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.38124\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.68551\n",
      "\u001b[32m[1221 13:22:49 @monitor.py:459]\u001b[0m valid_mean_dice: 0.59235\n",
      "\u001b[32m[1221 13:22:49 @group.py:48]\u001b[0m Callbacks took 27.936 sec in total. DataParallelInferenceRunner: 24.9 seconds\n",
      "\u001b[32m[1221 13:22:49 @base.py:272]\u001b[0m Start Epoch 20 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:30:18 @base.py:282]\u001b[0m Epoch 20 (global_step 15740) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:30:20 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-15740.\n",
      "\u001b[32m[1221 13:30:20 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=15740, aux_loss_dw changes from 0.052632 to 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m aux_loss_dw: 0.052632\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m l2_wd_loss: 0.015377\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m loss-bce-0: 0.1109\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m loss-bce-1: 0.0063274\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m loss-bce-2: 0.0065105\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m loss-bce-3: 0.0071491\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m overall_cost: 0.14626\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m valid_acc: 0.97563\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m valid_dice: 0.85671\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.59399\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.74281\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.42496\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70183\n",
      "\u001b[32m[1221 13:30:46 @monitor.py:459]\u001b[0m valid_mean_dice: 0.6159\n",
      "\u001b[32m[1221 13:30:46 @group.py:48]\u001b[0m Callbacks took 28.486 sec in total. DataParallelInferenceRunner: 26 seconds\n",
      "\u001b[32m[1221 13:30:46 @base.py:272]\u001b[0m Start Epoch 21 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:38:16 @base.py:282]\u001b[0m Epoch 21 (global_step 16527) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:38:19 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-16527.\n",
      "\u001b[32m[1221 13:38:19 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=16527, aux_loss_dw changes from 0.050000 to 0.047619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m aux_loss_dw: 0.05\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m l2_wd_loss: 0.015012\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m loss-bce-0: 0.11325\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m loss-bce-1: 0.0061473\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m loss-bce-2: 0.006258\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m loss-bce-3: 0.0069389\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m overall_cost: 0.1476\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m valid_acc: 0.97601\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m valid_dice: 0.85717\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.58714\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75328\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.45703\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.66244\n",
      "\u001b[32m[1221 13:38:44 @monitor.py:459]\u001b[0m valid_mean_dice: 0.61497\n",
      "\u001b[32m[1221 13:38:44 @group.py:48]\u001b[0m Callbacks took 27.618 sec in total. DataParallelInferenceRunner: 25.1 seconds\n",
      "\u001b[32m[1221 13:38:44 @base.py:272]\u001b[0m Start Epoch 22 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:46:13 @base.py:282]\u001b[0m Epoch 22 (global_step 17314) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:46:16 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-17314.\n",
      "\u001b[32m[1221 13:46:16 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=17314, aux_loss_dw changes from 0.047619 to 0.045455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m aux_loss_dw: 0.047619\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m l2_wd_loss: 0.014738\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m loss-bce-0: 0.11892\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m loss-bce-1: 0.0061753\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m loss-bce-2: 0.0062394\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m loss-bce-3: 0.0068786\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m overall_cost: 0.15295\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m valid_acc: 0.97585\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m valid_dice: 0.85671\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.53008\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.74769\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.46313\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70352\n",
      "\u001b[32m[1221 13:46:41 @monitor.py:459]\u001b[0m valid_mean_dice: 0.61111\n",
      "\u001b[32m[1221 13:46:41 @group.py:48]\u001b[0m Callbacks took 27.811 sec in total. DataParallelInferenceRunner: 25.3 seconds\n",
      "\u001b[32m[1221 13:46:41 @base.py:272]\u001b[0m Start Epoch 23 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:54:11 @base.py:282]\u001b[0m Epoch 23 (global_step 18101) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:54:14 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-18101.\n",
      "\u001b[32m[1221 13:54:14 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=18101, aux_loss_dw changes from 0.045455 to 0.043478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m aux_loss_dw: 0.045455\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m l2_wd_loss: 0.014471\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m loss-bce-0: 0.11109\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m loss-bce-1: 0.0055074\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m loss-bce-2: 0.0055517\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m loss-bce-3: 0.0061583\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m overall_cost: 0.14278\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m valid_acc: 0.97577\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m valid_dice: 0.85605\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.57513\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75165\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.42418\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.68427\n",
      "\u001b[32m[1221 13:54:40 @monitor.py:459]\u001b[0m valid_mean_dice: 0.60881\n",
      "\u001b[32m[1221 13:54:40 @group.py:48]\u001b[0m Callbacks took 28.647 sec in total. DataParallelInferenceRunner: 26 seconds\n",
      "\u001b[32m[1221 13:54:40 @base.py:272]\u001b[0m Start Epoch 24 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:02:09 @base.py:282]\u001b[0m Epoch 24 (global_step 18888) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:02:12 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-18888.\n",
      "\u001b[32m[1221 14:02:12 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=18888, aux_loss_dw changes from 0.043478 to 0.041667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m aux_loss_dw: 0.043478\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m l2_wd_loss: 0.014194\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m loss-bce-0: 0.11361\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m loss-bce-1: 0.0054147\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m loss-bce-2: 0.0054603\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m loss-bce-3: 0.0060637\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m overall_cost: 0.14474\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m valid_acc: 0.97551\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m valid_dice: 0.85365\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.54658\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.74231\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.40393\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.69468\n",
      "\u001b[32m[1221 14:02:39 @monitor.py:459]\u001b[0m valid_mean_dice: 0.59688\n",
      "\u001b[32m[1221 14:02:39 @group.py:48]\u001b[0m Callbacks took 29.598 sec in total. DataParallelInferenceRunner: 27 seconds\n",
      "\u001b[32m[1221 14:02:39 @base.py:272]\u001b[0m Start Epoch 25 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:10:09 @base.py:282]\u001b[0m Epoch 25 (global_step 19675) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:10:11 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-19675.\n",
      "\u001b[32m[1221 14:10:11 @param.py:158]\u001b[0m [HyperParamSetter] At global_step=19675, learning_rate is set to 0.000010\n",
      "\u001b[32m[1221 14:10:12 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=19675, aux_loss_dw changes from 0.041667 to 0.040000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m aux_loss_dw: 0.041667\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m l2_wd_loss: 0.014115\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m loss-bce-0: 0.11836\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m loss-bce-1: 0.0054079\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m loss-bce-2: 0.0054294\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m loss-bce-3: 0.0060497\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m overall_cost: 0.14937\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m valid_acc: 0.97564\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m valid_dice: 0.85742\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.5509\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.76406\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.44356\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.69219\n",
      "\u001b[32m[1221 14:10:38 @monitor.py:459]\u001b[0m valid_mean_dice: 0.61268\n",
      "\u001b[32m[1221 14:10:38 @group.py:48]\u001b[0m Callbacks took 29.301 sec in total. DataParallelInferenceRunner: 26.5 seconds\n",
      "\u001b[32m[1221 14:10:38 @base.py:272]\u001b[0m Start Epoch 26 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:18:07 @base.py:282]\u001b[0m Epoch 26 (global_step 20462) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:18:10 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-20462.\n",
      "\u001b[32m[1221 14:18:10 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=20462, aux_loss_dw changes from 0.040000 to 0.038462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m aux_loss_dw: 0.04\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m l2_wd_loss: 0.013959\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m loss-bce-0: 0.10329\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m loss-bce-1: 0.004519\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m loss-bce-2: 0.0045748\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m loss-bce-3: 0.0051687\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m overall_cost: 0.13151\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m valid_acc: 0.97621\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m valid_dice: 0.85884\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.58793\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75841\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.48377\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.69422\n",
      "\u001b[32m[1221 14:18:36 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63108\n",
      "\u001b[32m[1221 14:18:36 @group.py:48]\u001b[0m Callbacks took 29.180 sec in total. DataParallelInferenceRunner: 26.4 seconds\n",
      "\u001b[32m[1221 14:18:36 @base.py:272]\u001b[0m Start Epoch 27 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:26:06 @base.py:282]\u001b[0m Epoch 27 (global_step 21249) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:26:08 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-21249.\n",
      "\u001b[32m[1221 14:26:08 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=21249, aux_loss_dw changes from 0.038462 to 0.037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m aux_loss_dw: 0.038462\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m l2_wd_loss: 0.013832\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m loss-bce-0: 0.10742\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m loss-bce-1: 0.004524\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m loss-bce-2: 0.0045795\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m loss-bce-3: 0.0051214\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m overall_cost: 0.13548\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m valid_acc: 0.97613\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m valid_dice: 0.85913\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.60629\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75408\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.46693\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70714\n",
      "\u001b[32m[1221 14:26:34 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63361\n",
      "\u001b[32m[1221 14:26:34 @group.py:48]\u001b[0m Callbacks took 28.086 sec in total. DataParallelInferenceRunner: 25.6 seconds\n",
      "\u001b[32m[1221 14:26:34 @base.py:272]\u001b[0m Start Epoch 28 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:34:04 @base.py:282]\u001b[0m Epoch 28 (global_step 22036) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:34:06 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-22036.\n",
      "\u001b[32m[1221 14:34:06 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=22036, aux_loss_dw changes from 0.037037 to 0.035714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m aux_loss_dw: 0.037037\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m l2_wd_loss: 0.013718\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m loss-bce-0: 0.10492\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m loss-bce-1: 0.0042265\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m loss-bce-2: 0.0042962\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m loss-bce-3: 0.0047971\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m overall_cost: 0.13195\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m valid_acc: 0.97612\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m valid_dice: 0.85832\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.59427\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75393\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.46955\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70648\n",
      "\u001b[32m[1221 14:34:32 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63106\n",
      "\u001b[32m[1221 14:34:32 @group.py:48]\u001b[0m Callbacks took 27.889 sec in total. DataParallelInferenceRunner: 25.3 seconds\n",
      "\u001b[32m[1221 14:34:32 @base.py:272]\u001b[0m Start Epoch 29 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:42:01 @base.py:282]\u001b[0m Epoch 29 (global_step 22823) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:42:04 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-22823.\n",
      "\u001b[32m[1221 14:42:04 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=22823, aux_loss_dw changes from 0.035714 to 0.034483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m aux_loss_dw: 0.035714\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m l2_wd_loss: 0.013617\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m loss-bce-0: 0.097544\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m loss-bce-1: 0.003804\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m loss-bce-2: 0.0038492\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m loss-bce-3: 0.004377\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m overall_cost: 0.12319\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m valid_acc: 0.9762\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m valid_dice: 0.85902\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.60666\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.76313\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.48334\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.708\n",
      "\u001b[32m[1221 14:42:29 @monitor.py:459]\u001b[0m valid_mean_dice: 0.64028\n",
      "\u001b[32m[1221 14:42:29 @group.py:48]\u001b[0m Callbacks took 28.374 sec in total. DataParallelInferenceRunner: 25.1 seconds\n",
      "\u001b[32m[1221 14:42:29 @base.py:272]\u001b[0m Start Epoch 30 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:49:59 @base.py:282]\u001b[0m Epoch 30 (global_step 23610) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:50:02 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-23610.\n",
      "\u001b[32m[1221 14:50:02 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=23610, aux_loss_dw changes from 0.034483 to 0.033333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m aux_loss_dw: 0.034483\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m l2_wd_loss: 0.013523\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m loss-bce-0: 0.10557\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m loss-bce-1: 0.0039703\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m loss-bce-2: 0.0040121\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m loss-bce-3: 0.0045372\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m overall_cost: 0.13161\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m valid_acc: 0.97611\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m valid_dice: 0.85885\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.61004\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75139\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.47757\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70994\n",
      "\u001b[32m[1221 14:50:27 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63724\n",
      "\u001b[32m[1221 14:50:27 @group.py:48]\u001b[0m Callbacks took 28.034 sec in total. DataParallelInferenceRunner: 25.3 seconds\n",
      "\u001b[32m[1221 14:50:27 @base.py:272]\u001b[0m Start Epoch 31 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:57:56 @base.py:282]\u001b[0m Epoch 31 (global_step 24397) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:57:59 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-24397.\n",
      "\u001b[32m[1221 14:57:59 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=24397, aux_loss_dw changes from 0.033333 to 0.032258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m aux_loss_dw: 0.033333\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m l2_wd_loss: 0.013443\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m loss-bce-0: 0.10487\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m loss-bce-1: 0.003799\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m loss-bce-2: 0.0038534\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m loss-bce-3: 0.0043776\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m overall_cost: 0.13034\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m valid_acc: 0.97628\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m valid_dice: 0.85932\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.61047\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.76085\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.46547\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.7158\n",
      "\u001b[32m[1221 14:58:25 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63815\n",
      "\u001b[32m[1221 14:58:25 @group.py:48]\u001b[0m Callbacks took 28.142 sec in total. DataParallelInferenceRunner: 25.3 seconds\n",
      "\u001b[32m[1221 14:58:25 @base.py:272]\u001b[0m Start Epoch 32 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:05:54 @base.py:282]\u001b[0m Epoch 32 (global_step 25184) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:05:57 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-25184.\n",
      "\u001b[32m[1221 15:05:57 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=25184, aux_loss_dw changes from 0.032258 to 0.031250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m aux_loss_dw: 0.032258\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m l2_wd_loss: 0.013372\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m loss-bce-0: 0.11128\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m loss-bce-1: 0.003895\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m loss-bce-2: 0.0039568\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m loss-bce-3: 0.004467\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m overall_cost: 0.13697\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m valid_acc: 0.97622\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m valid_dice: 0.85941\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.60491\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.76419\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.47365\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70348\n",
      "\u001b[32m[1221 15:06:22 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63656\n",
      "\u001b[32m[1221 15:06:22 @group.py:48]\u001b[0m Callbacks took 27.628 sec in total. DataParallelInferenceRunner: 25 seconds\n",
      "\u001b[32m[1221 15:06:22 @base.py:272]\u001b[0m Start Epoch 33 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:13:51 @base.py:282]\u001b[0m Epoch 33 (global_step 25971) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:13:54 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-25971.\n",
      "\u001b[32m[1221 15:13:54 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=25971, aux_loss_dw changes from 0.031250 to 0.030303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:14:23 @saver.py:159]\u001b[0m Model at global_step=25971 with maximum valid_dice=0.86272 saved.\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m aux_loss_dw: 0.03125\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m l2_wd_loss: 0.013307\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m loss-bce-0: 0.11089\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m loss-bce-1: 0.0037912\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m loss-bce-2: 0.003843\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m loss-bce-3: 0.0043625\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m overall_cost: 0.13619\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m valid_acc: 0.9763\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m valid_dice: 0.86272\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.61782\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.76151\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.48372\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70573\n",
      "\u001b[32m[1221 15:14:23 @monitor.py:459]\u001b[0m valid_mean_dice: 0.6422\n",
      "\u001b[32m[1221 15:14:23 @group.py:48]\u001b[0m Callbacks took 31.858 sec in total. DataParallelInferenceRunner: 27.7 seconds\n",
      "\u001b[32m[1221 15:14:23 @base.py:272]\u001b[0m Start Epoch 34 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:21:53 @base.py:282]\u001b[0m Epoch 34 (global_step 26758) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:21:56 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-26758.\n",
      "\u001b[32m[1221 15:21:56 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=26758, aux_loss_dw changes from 0.030303 to 0.029412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m aux_loss_dw: 0.030303\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m l2_wd_loss: 0.013249\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m loss-bce-0: 0.10598\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m loss-bce-1: 0.0034733\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m loss-bce-2: 0.0035236\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m loss-bce-3: 0.0040061\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m overall_cost: 0.13024\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m valid_acc: 0.9763\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m valid_dice: 0.85976\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.61178\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.76357\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.47682\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70679\n",
      "\u001b[32m[1221 15:22:23 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63974\n",
      "\u001b[32m[1221 15:22:23 @group.py:48]\u001b[0m Callbacks took 30.067 sec in total. DataParallelInferenceRunner: 26.9 seconds\n",
      "\u001b[32m[1221 15:22:23 @base.py:272]\u001b[0m Start Epoch 35 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:29:53 @base.py:282]\u001b[0m Epoch 35 (global_step 27545) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:29:56 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-27545.\n",
      "\u001b[32m[1221 15:29:56 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=27545, aux_loss_dw changes from 0.029412 to 0.028571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m aux_loss_dw: 0.029412\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m l2_wd_loss: 0.013198\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m loss-bce-0: 0.10824\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m loss-bce-1: 0.0034784\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m loss-bce-2: 0.003506\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m loss-bce-3: 0.0039539\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m overall_cost: 0.13238\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m valid_acc: 0.97646\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m valid_dice: 0.86014\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.61128\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75656\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.4974\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70776\n",
      "\u001b[32m[1221 15:30:24 @monitor.py:459]\u001b[0m valid_mean_dice: 0.64325\n",
      "\u001b[32m[1221 15:30:24 @group.py:48]\u001b[0m Callbacks took 30.791 sec in total. DataParallelInferenceRunner: 27.8 seconds\n",
      "\u001b[32m[1221 15:30:24 @base.py:272]\u001b[0m Start Epoch 36 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:37:53 @base.py:282]\u001b[0m Epoch 36 (global_step 28332) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:37:56 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-28332.\n",
      "\u001b[32m[1221 15:37:56 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=28332, aux_loss_dw changes from 0.028571 to 0.027778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m aux_loss_dw: 0.028571\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m l2_wd_loss: 0.013146\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m loss-bce-0: 0.10396\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m loss-bce-1: 0.0032532\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m loss-bce-2: 0.0032912\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m loss-bce-3: 0.0037165\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m overall_cost: 0.12737\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m valid_acc: 0.97609\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m valid_dice: 0.85818\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.59181\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75832\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.48033\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70372\n",
      "\u001b[32m[1221 15:38:23 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63354\n",
      "\u001b[32m[1221 15:38:23 @group.py:48]\u001b[0m Callbacks took 29.598 sec in total. DataParallelInferenceRunner: 26.9 seconds\n",
      "\u001b[32m[1221 15:38:23 @base.py:272]\u001b[0m Start Epoch 37 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:45:52 @base.py:282]\u001b[0m Epoch 37 (global_step 29119) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:45:55 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-29119.\n",
      "\u001b[32m[1221 15:45:55 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=29119, aux_loss_dw changes from 0.027778 to 0.027027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:17<00:00, 3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m aux_loss_dw: 0.027778\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m l2_wd_loss: 0.013098\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m loss-bce-0: 0.10452\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m loss-bce-1: 0.0031711\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m loss-bce-2: 0.0032315\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m loss-bce-3: 0.0036774\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m overall_cost: 0.12769\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m valid_acc: 0.97584\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m valid_dice: 0.85694\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.59464\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75484\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.47907\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70471\n",
      "\u001b[32m[1221 15:46:22 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63332\n",
      "\u001b[32m[1221 15:46:22 @group.py:48]\u001b[0m Callbacks took 30.113 sec in total. DataParallelInferenceRunner: 27.3 seconds\n",
      "\u001b[32m[1221 15:46:22 @base.py:272]\u001b[0m Start Epoch 38 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:53:51 @base.py:282]\u001b[0m Epoch 38 (global_step 29906) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:53:54 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-29906.\n",
      "\u001b[32m[1221 15:53:54 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=29906, aux_loss_dw changes from 0.027027 to 0.026316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m aux_loss_dw: 0.027027\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m l2_wd_loss: 0.01305\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m loss-bce-0: 0.10022\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m loss-bce-1: 0.0029625\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m loss-bce-2: 0.0029912\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m loss-bce-3: 0.00338\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m overall_cost: 0.12261\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m valid_acc: 0.97636\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m valid_dice: 0.86109\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.6135\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75875\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.49812\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.7112\n",
      "\u001b[32m[1221 15:54:20 @monitor.py:459]\u001b[0m valid_mean_dice: 0.64539\n",
      "\u001b[32m[1221 15:54:20 @group.py:48]\u001b[0m Callbacks took 28.947 sec in total. DataParallelInferenceRunner: 26 seconds\n",
      "\u001b[32m[1221 15:54:20 @base.py:272]\u001b[0m Start Epoch 39 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:01:50 @base.py:282]\u001b[0m Epoch 39 (global_step 30693) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:01:52 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-30693.\n",
      "\u001b[32m[1221 16:01:52 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=30693, aux_loss_dw changes from 0.026316 to 0.025641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m aux_loss_dw: 0.026316\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m l2_wd_loss: 0.013007\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m loss-bce-0: 0.10243\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m loss-bce-1: 0.0029425\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m loss-bce-2: 0.002976\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m loss-bce-3: 0.0034101\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m overall_cost: 0.12477\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m valid_acc: 0.97612\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m valid_dice: 0.85807\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.60446\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.76167\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.48478\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70824\n",
      "\u001b[32m[1221 16:02:18 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63979\n",
      "\u001b[32m[1221 16:02:18 @group.py:48]\u001b[0m Callbacks took 28.323 sec in total. DataParallelInferenceRunner: 25.7 seconds\n",
      "\u001b[32m[1221 16:02:18 @base.py:272]\u001b[0m Start Epoch 40 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:09:47 @base.py:282]\u001b[0m Epoch 40 (global_step 31480) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:09:50 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-31480.\n",
      "\u001b[32m[1221 16:09:50 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=31480, aux_loss_dw changes from 0.025641 to 0.025000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:10:17 @saver.py:159]\u001b[0m Model at global_step=31480 with maximum valid_dice=0.8628 saved.\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m aux_loss_dw: 0.025641\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m l2_wd_loss: 0.012966\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m loss-bce-0: 0.10333\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m loss-bce-1: 0.0029157\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m loss-bce-2: 0.0029628\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m loss-bce-3: 0.0033895\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m overall_cost: 0.12556\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m valid_acc: 0.97655\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m valid_dice: 0.8628\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.61461\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.762\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.47762\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.71121\n",
      "\u001b[32m[1221 16:10:17 @monitor.py:459]\u001b[0m valid_mean_dice: 0.64136\n",
      "\u001b[32m[1221 16:10:17 @group.py:48]\u001b[0m Callbacks took 30.082 sec in total. DataParallelInferenceRunner: 25.8 seconds\n",
      "\u001b[32m[1221 16:10:17 @base.py:272]\u001b[0m Start Epoch 41 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:17:47 @base.py:282]\u001b[0m Epoch 41 (global_step 32267) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:17:50 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-32267.\n",
      "\u001b[32m[1221 16:17:50 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=32267, aux_loss_dw changes from 0.025000 to 0.024390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:17<00:00, 3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m aux_loss_dw: 0.025\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m l2_wd_loss: 0.012924\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m loss-bce-0: 0.10498\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m loss-bce-1: 0.0028665\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m loss-bce-2: 0.002921\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m loss-bce-3: 0.0033447\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m overall_cost: 0.12704\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m valid_acc: 0.97614\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m valid_dice: 0.85714\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.60394\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75607\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.486\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.7092\n",
      "\u001b[32m[1221 16:18:16 @monitor.py:459]\u001b[0m valid_mean_dice: 0.6388\n",
      "\u001b[32m[1221 16:18:16 @group.py:48]\u001b[0m Callbacks took 28.663 sec in total. DataParallelInferenceRunner: 25.8 seconds\n",
      "\u001b[32m[1221 16:18:16 @base.py:272]\u001b[0m Start Epoch 42 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:25:45 @base.py:282]\u001b[0m Epoch 42 (global_step 33054) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:25:48 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-33054.\n",
      "\u001b[32m[1221 16:25:48 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=33054, aux_loss_dw changes from 0.024390 to 0.023810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m aux_loss_dw: 0.02439\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m l2_wd_loss: 0.012886\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m loss-bce-0: 0.10535\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m loss-bce-1: 0.0028003\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m loss-bce-2: 0.0028601\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m loss-bce-3: 0.0032614\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m overall_cost: 0.12716\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m valid_acc: 0.9765\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m valid_dice: 0.86215\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.62254\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75746\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.49386\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.71731\n",
      "\u001b[32m[1221 16:26:15 @monitor.py:459]\u001b[0m valid_mean_dice: 0.64779\n",
      "\u001b[32m[1221 16:26:15 @group.py:48]\u001b[0m Callbacks took 29.194 sec in total. DataParallelInferenceRunner: 26.7 seconds\n",
      "\u001b[32m[1221 16:26:15 @base.py:272]\u001b[0m Start Epoch 43 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:33:44 @base.py:282]\u001b[0m Epoch 43 (global_step 33841) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:33:46 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-33841.\n",
      "\u001b[32m[1221 16:33:46 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=33841, aux_loss_dw changes from 0.023810 to 0.023256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:17<00:00, 3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m aux_loss_dw: 0.02381\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m l2_wd_loss: 0.012846\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m loss-bce-0: 0.10194\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m loss-bce-1: 0.002661\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m loss-bce-2: 0.0027007\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m loss-bce-3: 0.0030598\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m overall_cost: 0.12321\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m valid_acc: 0.9762\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m valid_dice: 0.8584\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.60651\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75605\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.47924\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70769\n",
      "\u001b[32m[1221 16:34:13 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63737\n",
      "\u001b[32m[1221 16:34:13 @group.py:48]\u001b[0m Callbacks took 29.186 sec in total. DataParallelInferenceRunner: 26.6 seconds\n",
      "\u001b[32m[1221 16:34:13 @base.py:272]\u001b[0m Start Epoch 44 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:41:42 @base.py:282]\u001b[0m Epoch 44 (global_step 34628) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:41:45 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-34628.\n",
      "\u001b[32m[1221 16:41:45 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=34628, aux_loss_dw changes from 0.023256 to 0.022727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m aux_loss_dw: 0.023256\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m l2_wd_loss: 0.01281\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m loss-bce-0: 0.1025\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m loss-bce-1: 0.0026186\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m loss-bce-2: 0.002635\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m loss-bce-3: 0.0030075\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m overall_cost: 0.12357\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m valid_acc: 0.97658\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m valid_dice: 0.86162\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.61354\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75597\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.50371\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.69092\n",
      "\u001b[32m[1221 16:42:11 @monitor.py:459]\u001b[0m valid_mean_dice: 0.64103\n",
      "\u001b[32m[1221 16:42:11 @group.py:48]\u001b[0m Callbacks took 28.861 sec in total. DataParallelInferenceRunner: 26.3 seconds\n",
      "\u001b[32m[1221 16:42:11 @base.py:272]\u001b[0m Start Epoch 45 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:49:40 @base.py:282]\u001b[0m Epoch 45 (global_step 35415) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:49:43 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-35415.\n",
      "\u001b[32m[1221 16:49:43 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=35415, aux_loss_dw changes from 0.022727 to 0.022222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m aux_loss_dw: 0.022727\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m l2_wd_loss: 0.012775\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m loss-bce-0: 0.10299\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m loss-bce-1: 0.0025614\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m loss-bce-2: 0.0025937\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m loss-bce-3: 0.0029478\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m overall_cost: 0.12387\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m valid_acc: 0.97615\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m valid_dice: 0.86007\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.60773\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75829\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.47414\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70561\n",
      "\u001b[32m[1221 16:50:10 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63644\n",
      "\u001b[32m[1221 16:50:10 @group.py:48]\u001b[0m Callbacks took 29.553 sec in total. DataParallelInferenceRunner: 27 seconds\n",
      "\u001b[32m[1221 16:50:10 @base.py:272]\u001b[0m Start Epoch 46 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:57:40 @base.py:282]\u001b[0m Epoch 46 (global_step 36202) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:57:42 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-36202.\n",
      "\u001b[32m[1221 16:57:42 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=36202, aux_loss_dw changes from 0.022222 to 0.021739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m aux_loss_dw: 0.022222\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m l2_wd_loss: 0.012739\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m loss-bce-0: 0.10377\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m loss-bce-1: 0.0025205\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m loss-bce-2: 0.0025574\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m loss-bce-3: 0.0029447\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m overall_cost: 0.12454\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m valid_acc: 0.9764\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m valid_dice: 0.86198\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.61556\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75644\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.48143\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.71238\n",
      "\u001b[32m[1221 16:58:08 @monitor.py:459]\u001b[0m valid_mean_dice: 0.64145\n",
      "\u001b[32m[1221 16:58:08 @group.py:48]\u001b[0m Callbacks took 28.030 sec in total. DataParallelInferenceRunner: 25.5 seconds\n",
      "\u001b[32m[1221 16:58:08 @base.py:272]\u001b[0m Start Epoch 47 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 17:05:38 @base.py:282]\u001b[0m Epoch 47 (global_step 36989) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 17:05:40 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-36989.\n",
      "\u001b[32m[1221 17:05:40 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=36989, aux_loss_dw changes from 0.021739 to 0.021277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m aux_loss_dw: 0.021739\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m l2_wd_loss: 0.012708\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m loss-bce-0: 0.10372\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m loss-bce-1: 0.0024621\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m loss-bce-2: 0.0025101\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m loss-bce-3: 0.0028562\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m overall_cost: 0.12426\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m valid_acc: 0.9762\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m valid_dice: 0.85973\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.59648\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.76122\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.47466\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70738\n",
      "\u001b[32m[1221 17:06:06 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63494\n",
      "\u001b[32m[1221 17:06:06 @group.py:48]\u001b[0m Callbacks took 28.585 sec in total. DataParallelInferenceRunner: 25.8 seconds\n",
      "\u001b[32m[1221 17:06:06 @base.py:272]\u001b[0m Start Epoch 48 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 17:13:36 @base.py:282]\u001b[0m Epoch 48 (global_step 37776) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 17:13:39 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-37776.\n",
      "\u001b[32m[1221 17:13:39 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=37776, aux_loss_dw changes from 0.021277 to 0.020833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m aux_loss_dw: 0.021277\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m l2_wd_loss: 0.012675\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m loss-bce-0: 0.10065\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m loss-bce-1: 0.002351\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m loss-bce-2: 0.0023816\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m loss-bce-3: 0.0027261\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m overall_cost: 0.12079\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m valid_acc: 0.97619\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m valid_dice: 0.85879\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.60693\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.76118\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.50038\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70273\n",
      "\u001b[32m[1221 17:14:05 @monitor.py:459]\u001b[0m valid_mean_dice: 0.6428\n",
      "\u001b[32m[1221 17:14:05 @group.py:48]\u001b[0m Callbacks took 28.520 sec in total. DataParallelInferenceRunner: 25.5 seconds\n",
      "\u001b[32m[1221 17:14:05 @base.py:272]\u001b[0m Start Epoch 49 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 17:21:34 @base.py:282]\u001b[0m Epoch 49 (global_step 38563) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 17:21:37 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-38563.\n",
      "\u001b[32m[1221 17:21:37 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=38563, aux_loss_dw changes from 0.020833 to 0.020408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m aux_loss_dw: 0.020833\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m l2_wd_loss: 0.012644\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m loss-bce-0: 0.10211\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m loss-bce-1: 0.0023241\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m loss-bce-2: 0.0023631\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m loss-bce-3: 0.0027388\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m overall_cost: 0.12218\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m valid_acc: 0.97607\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m valid_dice: 0.85822\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.59186\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75439\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.48068\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70543\n",
      "\u001b[32m[1221 17:22:03 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63309\n",
      "\u001b[32m[1221 17:22:03 @group.py:48]\u001b[0m Callbacks took 29.177 sec in total. DataParallelInferenceRunner: 25.9 seconds\n",
      "\u001b[32m[1221 17:22:03 @base.py:272]\u001b[0m Start Epoch 50 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|787/787[07:29<00:00, 1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 17:29:33 @base.py:282]\u001b[0m Epoch 50 (global_step 39350) finished, time:7 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 17:29:37 @saver.py:77]\u001b[0m Model saved to ./logs//High_CCRCC//micronet_v/model-39350.\n",
      "\u001b[32m[1221 17:29:37 @param.py:161]\u001b[0m [HyperParamSetter] At global_step=39350, aux_loss_dw changes from 0.020408 to 0.020000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|57/57[00:16<00:00, 3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m aux_loss_dw: 0.020408\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m l2_wd_loss: 0.012612\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m loss-bce-0: 0.098575\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m loss-bce-1: 0.002225\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m loss-bce-2: 0.0022421\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m loss-bce-3: 0.0025715\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m overall_cost: 0.11823\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m valid_acc: 0.9761\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m valid_dice: 0.85895\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m valid_dice_Endothelium: 0.60213\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m valid_dice_Grade1: 0.75707\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m valid_dice_Grade2: 0.4856\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m valid_dice_Grade3: 0.70877\n",
      "\u001b[32m[1221 17:30:03 @monitor.py:459]\u001b[0m valid_mean_dice: 0.63839\n",
      "\u001b[32m[1221 17:30:03 @group.py:48]\u001b[0m Callbacks took 29.503 sec in total. DataParallelInferenceRunner: 25.7 seconds\n",
      "\u001b[32m[1221 17:30:03 @base.py:286]\u001b[0m Training has finished!\n",
      "\u001b[32m[1221 17:30:03 @input_source.py:174]\u001b[0m EnqueueThread QueueInput/input_queue Exited.\n",
      "\u001b[32m[1221 17:30:03 @input_source.py:174]\u001b[0m EnqueueThread DataParallelInferenceRunner/QueueInput/input_queue Exited.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer()\n",
    "gpus = \"2,3\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
    "nr_gpus = len(gpus.split(','))\n",
    "trainer.run(nr_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-hovernet] *",
   "language": "python",
   "name": "conda-env-.conda-hovernet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
