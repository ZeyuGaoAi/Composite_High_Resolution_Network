{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from infer import Inferer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = \"7\"\n",
    "n_gpus = len(gpus.split(','))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
    "inferer = Inferer()\n",
    "#inferer.run(n_gpus)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the predict results and Generate predict overlay images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import itertools\n",
    "from scipy import io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from misc.viz_utils import visualize_instances\n",
    "from postproc.hover import proc_np_hv\n",
    "\n",
    "def load_ground_trues(ann_dir, basename):\n",
    "    ann_inst = np.loadtxt(ann_dir + '/' + basename.replace('original','boundary') + '.txt', delimiter=',')\n",
    "    ann_type_list = list(np.loadtxt(ann_dir + '/' + basename.replace('original','boundary_label') + '.txt', delimiter=','))\n",
    "    ann_type = ann_inst.copy()\n",
    "    for i in range(len(ann_type_list)-1):\n",
    "        ann_type[ann_type==(i+1)] = ann_type_list[i+1]\n",
    "    ann_type[ann_type == 5] = 4\n",
    "    ann_type[ann_type == -1] = 0\n",
    "    ann_inst[ann_inst == -1] = 0\n",
    "    return ann_inst, ann_type\n",
    "\n",
    "def load_ground_trues_consep(ann_dir, basename):\n",
    "    ann = sio.loadmat(ann_dir + '/' + basename + '.mat')\n",
    "    ann_type = ann['type_map']\n",
    "    ann_inst = ann['inst_map']\n",
    "    ann_type[(ann_type == 3) | (ann_type == 4)] = 3\n",
    "    ann_type[(ann_type == 5) | (ann_type == 6) | (ann_type == 7)] = 4\n",
    "    return ann_inst, ann_type\n",
    "\n",
    "def load_ground_trues_monuseg(ann_dir, basename):\n",
    "    ann = np.load(ann_dir + '/' + basename + '.npy')\n",
    "    ann_type = ann.copy()\n",
    "    ann_type[ann_type!=0] = 1\n",
    "    ann_inst = ann\n",
    "    return ann_inst, ann_type\n",
    "\n",
    "def load_ground_trues_kumar(ann_dir, basename):\n",
    "    ann = sio.loadmat(ann_dir + '/' + basename + '.mat')\n",
    "    ann_inst = ann['inst_map']\n",
    "    ann_type = ann_inst.copy()\n",
    "    ann_type[ann_type!=0] = 1\n",
    "    return ann_inst, ann_type\n",
    "\n",
    "def class_colour(class_value):\n",
    "    \"\"\"\n",
    "    Generate RGB colour for overlay based on class id\n",
    "    Args:\n",
    "        class_value: integer denoting the class of object  \n",
    "    \"\"\"\n",
    "    if class_value == 0:\n",
    "        return 0, 0, 0  # black (background)\n",
    "    if class_value == 1:\n",
    "        return 0, 255, 0  # green\n",
    "    elif class_value == 2:\n",
    "        return 255, 255, 0  # yellow\n",
    "    elif class_value == 3:\n",
    "        return 255, 0, 0  # red\n",
    "    elif class_value == 4:\n",
    "        return 0, 0, 255  # blue\n",
    "    elif class_value == 5:\n",
    "        return 255, 165, 0  # orange\n",
    "    elif class_value == 6:\n",
    "        return 0, 255, 255  # cyan\n",
    "    else:\n",
    "        raise Exception(\n",
    "            'Currently, overlay_segmentation_results() only supports up to 6 classes.')\n",
    "####\n",
    "\n",
    "def process_instance(pred_map, nr_types=0, remap_label=False, output_dtype='uint16'):\n",
    "    \"\"\"\n",
    "    Post processing script for image tiles\n",
    "\n",
    "    Args:\n",
    "        pred_map: commbined output of nc, np and hv branches\n",
    "        nr_types: number of types considered at output of nc branch\n",
    "        remap_label: whether to map instance labels from 1 to N (N = number of nuclei)\n",
    "        output_dtype: data type of output\n",
    "    \n",
    "    Returns:\n",
    "        pred_inst:     pixel-wise nuclear instance segmentation prediction\n",
    "        pred_type_out: pixel-wise nuclear type prediction \n",
    "    \"\"\"\n",
    "\n",
    "    pred_inst = pred_map[..., nr_types:]\n",
    "    pred_inst = np.squeeze(pred_inst)\n",
    "    \n",
    "    pred_inst = proc_np_hv(pred_inst)\n",
    "\n",
    "    # remap label is very slow - only uncomment if necessary to map labels in order\n",
    "#     if remap_label:\n",
    "#         pred_inst = remap_label(pred_inst, by_size=True)\n",
    "    if nr_types != 0:\n",
    "        pred_type = pred_map[..., :nr_types]\n",
    "        pred_type = np.argmax(pred_type, axis=-1)\n",
    "        pred_type = np.squeeze(pred_type)\n",
    "\n",
    "        pred_type_out = np.zeros([pred_type.shape[0], pred_type.shape[1]])               \n",
    "        #### * Get class of each instance id, stored at index id-1\n",
    "        pred_id_list = list(np.unique(pred_inst))[1:] # exclude background ID\n",
    "        pred_inst_type = np.full(len(pred_id_list), 0, dtype=np.int32)\n",
    "        for idx, inst_id in enumerate(pred_id_list):\n",
    "            inst_tmp = pred_inst == inst_id\n",
    "            inst_type = pred_type[pred_inst == inst_id]\n",
    "            type_list, type_pixels = np.unique(inst_type, return_counts=True)\n",
    "            type_list = list(zip(type_list, type_pixels))\n",
    "            type_list = sorted(type_list, key=lambda x: x[1], reverse=True)\n",
    "            inst_type = type_list[0][0]\n",
    "            if inst_type == 0: # ! pick the 2nd most dominant if exist\n",
    "                if len(type_list) > 1:\n",
    "                    inst_type = type_list[1][0]\n",
    "            pred_type_out += (inst_tmp * inst_type)\n",
    "    else:\n",
    "        pred_type_out = pred_inst.copy()\n",
    "        pred_type_out[pred_type_out!=0] = 1\n",
    "    \n",
    "    return pred_inst.astype(output_dtype), pred_type_out.astype(output_dtype)\n",
    "\n",
    "def bounding_box(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    # due to python indexing, need to add 1 to max\n",
    "    # else accessing will be 1px in the box, not out \n",
    "    rmax += 1\n",
    "    cmax += 1\n",
    "    return [rmin, rmax, cmin, cmax]\n",
    "\n",
    "def visualize_instances(input_image, predict_instance, predict_type=None, line_thickness=2):\n",
    "    \"\"\"\n",
    "    Overlays segmentation results on image as contours\n",
    "    Args:\n",
    "        input_image: input image\n",
    "        predict_instance: instance mask with unique value for every object\n",
    "        predict_type: type mask with unique value for every class\n",
    "        line_thickness: line thickness of contours\n",
    "    Returns:\n",
    "        overlay: output image with segmentation overlay as contours\n",
    "    \"\"\"\n",
    "   \n",
    "    overlay = np.copy((input_image).astype(np.uint8))\n",
    "\n",
    "    if predict_type is not None:\n",
    "        type_list = list(np.unique(predict_type))  # get list of types\n",
    "        type_list.remove(0)  # remove background\n",
    "    else:\n",
    "        type_list = [4]  # yellow\n",
    "\n",
    "    for iter_type in type_list:\n",
    "        if predict_type is not None:\n",
    "            label_map = (predict_type == iter_type) * predict_instance\n",
    "        else:\n",
    "            label_map = predict_instance\n",
    "        instances_list = list(np.unique(label_map))  # get list of instances\n",
    "        instances_list.remove(0)  # remove background\n",
    "        contours = []\n",
    "        for inst_id in instances_list:\n",
    "            instance_map = np.array(\n",
    "                predict_instance == inst_id, np.uint8)  # get single object\n",
    "            y1, y2, x1, x2 = bounding_box(instance_map)\n",
    "            y1 = y1 - 2 if y1 - 2 >= 0 else y1\n",
    "            x1 = x1 - 2 if x1 - 2 >= 0 else x1\n",
    "            x2 = x2 + 2 if x2 + 2 <= predict_instance.shape[1] - 1 else x2\n",
    "            y2 = y2 + 2 if y2 + 2 <= predict_instance.shape[0] - 1 else y2\n",
    "            inst_map_crop = instance_map[y1:y2, x1:x2]\n",
    "            contours_crop = cv2.findContours(\n",
    "                inst_map_crop, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            index_correction = np.asarray([[[[x1, y1]]]])\n",
    "            for i in range(len(contours_crop[0])):\n",
    "                contours.append(\n",
    "                    list(np.asarray(contours_crop[0][i].astype('int32')) + index_correction))\n",
    "        contours = list(itertools.chain(*contours))\n",
    "        cv2.drawContours(overlay, np.asarray(contours), -1,\n",
    "                         class_colour(iter_type), line_thickness)\n",
    "    return overlay\n",
    "\n",
    "from pq_metrics import get_fast_pq, remap_label, binarize\n",
    "\n",
    "def cal_metrics(ann_inst, ann_type, pred_inst, pred_type):\n",
    "    bound_true = remap_label(ann_inst)\n",
    "    bound_pred = remap_label(pred_inst)\n",
    "    [dq, sq, pq_bin], _ = get_fast_pq(bound_true, bound_pred)\n",
    "\n",
    "    cls_true = ann_type\n",
    "    cls_pred = pred_type\n",
    "    pq = []\n",
    "    for c in range(1, inferer.nr_types):\n",
    "        temp_pred = bound_pred.copy()\n",
    "        temp_pred[cls_pred!=c] = 0\n",
    "        temp_pred = remap_label(temp_pred) \n",
    "        temp_true = bound_true.copy()\n",
    "        temp_true[cls_true!=c] = 0\n",
    "        temp_true = remap_label(temp_true)\n",
    "        if len(np.unique(temp_true)) == 1:\n",
    "            tmp_pq = np.nan\n",
    "        else:\n",
    "            [_, _, tmp_pq], _ = get_fast_pq(temp_true, temp_pred)\n",
    "        pq.append(tmp_pq)\n",
    "        # count tp fp\n",
    "        total[c-1] += len(np.unique(temp_true)-1)\n",
    "        predict[c-1] += len(np.unique(temp_pred)-1)\n",
    "        for j in np.unique(temp_true):\n",
    "            if j == 0:\n",
    "                continue\n",
    "            # 重叠>0.5 count\n",
    "            if np.count_nonzero(temp_pred[temp_true == j]) > temp_pred[temp_true == j].size*.5:\n",
    "                correct[c-1] += 1\n",
    "    return dq, sq, pq_bin, pq\n",
    "\n",
    "# pred_path = \"./output/CoNSeP/np_dg\"\n",
    "pred_path = \"/home1/sjb/ccrcc_grading/gaussianmap/result/Kumar/mcc_ssim_npy\"\n",
    "# img_path = \"/home1/gzy/NucleiSegmentation/MoNuSeg/Test/Images\"\n",
    "img_path = '/home1/gzy/NucleiSegmentation/Kumar/Test/Images'\n",
    "# save_dir = \"/home1/gzy/NucleiSegmentation/MoNuSeg/Predicts_Hover\"\n",
    "# ann_dir = \"/home1/gzy/NucleiSegmentation/MoNuSeg/Test/Labels\"\n",
    "ann_dir = '/home1/gzy/NucleiSegmentation/Kumar/Test/Labels'\n",
    "file_list = glob.glob('%s/*%s' % (img_path, '.png'))\n",
    "file_list.sort() # ensure same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/14 [00:11<02:25, 11.17s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-8d7533345435>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0ma_dice_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dice_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_inst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#a_dice_2 = get_fast_dice_2(ann_inst, pred_inst)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0ma_ajis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fast_aji\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_inst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_inst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0moverlaid_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HoverNet/hover_net-master/src/metrics/stats_utils.py\u001b[0m in \u001b[0;36mget_fast_aji\u001b[0;34m(true, pred)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrue_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrue_id_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 0-th is background\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mpred_true_overlap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_mask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mpred_true_overlap_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_true_overlap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mpred_true_overlap_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_true_overlap_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from metrics.stats_utils import get_fast_aji, get_dice_1, get_dice_2, get_fast_dice_2\n",
    "bpq_all = []\n",
    "mpq_all = []\n",
    "dq_all =[]\n",
    "sq_all = []\n",
    "aji_all = []\n",
    "dice_1_all = []\n",
    "dice_2_all = []\n",
    "type_names = ['Miscellaneous','Inflammatory','Epithelial','Spindle']\n",
    "total = [0 for i in range(inferer.nr_types-1)]\n",
    "correct = [0 for i in range(inferer.nr_types-1)]\n",
    "predict = [0 for i in range(inferer.nr_types-1)]\n",
    "\n",
    "for filename in tqdm(file_list):\n",
    "    filename = os.path.basename(filename)\n",
    "    basename = os.path.splitext(filename)[0]\n",
    "    \n",
    "    img = cv2.imread(img_path + '/' + filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    ann_inst, ann_type = load_ground_trues_kumar(ann_dir, basename)\n",
    "    ann_inst = remap_label(ann_inst)\n",
    "    \n",
    "    # load hover results\n",
    "#     pred = sio.loadmat(pred_path + '/' + basename + '.mat')\n",
    "#     pred = pred['result']\n",
    "#     pred_inst, pred_type = process_instance(pred, nr_types=0)\n",
    "#     pred_inst, pred_type = process_instance(pred, nr_types=inferer.nr_types)\n",
    "    \n",
    "    # load dg results\n",
    "    pred = np.load(pred_path + '/' + basename + '.npy')\n",
    "    pred[pred==1] = 0\n",
    "    pred[pred==-1] = 0\n",
    "    pred = remap_label(pred)\n",
    "    pred_inst = pred\n",
    "    pred_type = pred.copy()\n",
    "    pred_type[pred_type!=0] = 1\n",
    "    \n",
    "    a_dice_1 = get_dice_1(ann_inst, pred_inst)\n",
    "    #a_dice_2 = get_fast_dice_2(ann_inst, pred_inst)\n",
    "    a_ajis = get_fast_aji(ann_inst.astype('int'), pred_inst.astype('int'))\n",
    "\n",
    "    overlaid_output = visualize_instances(img, pred_inst, pred_type)\n",
    "    overlaid_output = cv2.cvtColor(overlaid_output, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #cv2.imwrite('%s/%s.png' % (save_dir, basename), overlaid_output)\n",
    "    \n",
    "    dq, sq, bpq, mpq = cal_metrics(ann_inst, ann_type, pred_inst, pred_type)\n",
    "    bpq_all.append(bpq)\n",
    "    mpq_all.append(mpq)\n",
    "    dq_all.append(dq)\n",
    "    sq_all.append(sq)\n",
    "    aji_all.append(a_ajis)\n",
    "    dice_1_all.append(a_dice_1)\n",
    "    #dice_2_all.append(a_dice_2)\n",
    "\n",
    "grade1_PQ = np.nanmean([pq[0] for pq in mpq_all])\n",
    "grade2_PQ = np.nanmean([pq[1] for pq in mpq_all])\n",
    "grade3_PQ = np.nanmean([pq[2] for pq in mpq_all])\n",
    "endothelium_PQ = np.nanmean([pq[3] for pq in mpq_all])\n",
    "mpq_each_image = [np.nanmean(pq) for pq in mpq_all]\n",
    "\n",
    "recall_pc = [correct[i]/total[i] for i in range(len(correct))]\n",
    "precision_pc = [correct[i]/predict[i] for i in range(len(correct))]\n",
    "\n",
    "recall = np.sum(correct)/np.sum(total)\n",
    "precision = np.sum(correct)/np.sum(predict)\n",
    "F1 = 2*recall*precision/(precision+recall)\n",
    "\n",
    "print(\"The AJI is %.4f, The Dice1 is %.4f\" % (np.nanmean(aji_all), np.nanmean(dice_1_all)))\n",
    "\n",
    "print(\"The DQ is %.4f, The SQ is %.4f\" % (np.nanmean(dq_all), np.nanmean(sq_all)))\n",
    "\n",
    "print(\"The binary PQ is %.4f, The mean PQ is %.4f,\\nThe PQ of %s is %.4f,\\\n",
    "        \\nThe PQ of %s is %.4f, \\nThe PQ of %s is %.4f, \\nThe PQ of %s is %.4f\"\n",
    "      % (np.nanmean(bpq_all), np.nanmean(mpq_each_image), type_names[0], np.nanmean(grade1_PQ),\n",
    "         type_names[1], np.nanmean(grade2_PQ), type_names[2], np.nanmean(grade3_PQ),\n",
    "         type_names[3], np.nanmean(endothelium_PQ)))\n",
    "\n",
    "print(\"Precision: %.4f, Recall: %.4f, F1: %.4f\" % (precision, recall, F1))\n",
    "print(\"            Pricision    Recall    F1\")\n",
    "print(\"%s:   %.4f      %.4f    %.4f\" % (type_names[0], precision_pc[0], recall_pc[0], 2*recall_pc[0]*precision_pc[0]/(precision_pc[0]+recall_pc[0])))\n",
    "print(\"%s:   %.4f      %.4f    %.4f\" % (type_names[1], precision_pc[1], recall_pc[1], 2*recall_pc[1]*precision_pc[1]/(precision_pc[1]+recall_pc[1])))\n",
    "print(\"%s:   %.4f      %.4f    %.4f\" % (type_names[2], precision_pc[2], recall_pc[2], 2*recall_pc[2]*precision_pc[2]/(precision_pc[2]+recall_pc[2])))\n",
    "print(\"%s:   %.4f      %.4f    %.4f\" % (type_names[3], precision_pc[3], recall_pc[3], 2*recall_pc[3]*precision_pc[3]/(precision_pc[3]+recall_pc[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ann_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:10<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# 生成预测overlap图\n",
    "for filename in tqdm(file_list):\n",
    "    filename = os.path.basename(filename)\n",
    "    basename = os.path.splitext(filename)[0]\n",
    "    img = cv2.imread(img_path + '/' + filename)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pred = sio.loadmat(pred_path + '/' + basename + '.mat')\n",
    "    pred = pred['result']\n",
    "#     ann_inst, ann_type = load_ground_trues_consep(ann_dir, basename)\n",
    "\n",
    "#     pred_inst, pred_type = process_instance(pred, nr_types=inferer.nr_types)\n",
    "    pred_inst, pred_type = process_instance(pred, nr_types=0)\n",
    "\n",
    "    overlaid_output = visualize_instances(img, pred_inst, pred_type)\n",
    "    overlaid_output = cv2.cvtColor(overlaid_output, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cv2.imwrite('%s/%s_hover_predict.png' % (save_dir, basename), overlaid_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 12.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# 生成预测高斯结果图\n",
    "for filename in tqdm(file_list):\n",
    "    filename = os.path.basename(filename)\n",
    "    basename = os.path.splitext(filename)[0]\n",
    "    pred = sio.loadmat(pred_path + '/' + basename + '.mat')\n",
    "    pred = pred['result']\n",
    "    p_map = pred[0][:,:,-2]\n",
    "#     p_map = (p_map - p_map.min())/(p_map.max() - p_map.min())\n",
    "    n_map = pred[0][:,:,-1]\n",
    "#     n_map = (n_map - n_map.min())/(n_map.max() - n_map.min())\n",
    "#     cv2.imwrite('%s/%s.png' % (save_dir+'/binary/', basename), pred[0][:,:,0]*255)\n",
    "\n",
    "#     pred_type = np.argmax(pred[0][...,:3], axis=-1)\n",
    "#     band_1 = np.zeros_like(pred_type)\n",
    "#     band_2 = np.zeros_like(pred_type)\n",
    "#     band_3 = np.zeros_like(pred_type)\n",
    "#     band_1[pred_type==1] = 255\n",
    "#     band_2[pred_type==2] = 255\n",
    "#     band_1 = np.expand_dims(band_1, -1)\n",
    "#     band_2 = np.expand_dims(band_2, -1)\n",
    "#     band_3 = np.expand_dims(band_3, -1)\n",
    "#     pred_type = np.concatenate((band_1, band_2, band_3), axis=-1)\n",
    "    \n",
    "#     cv2.imwrite('%s/%s_b.png' % (save_dir+'/result_mae_bnd/', basename), pred_type)\n",
    "    cv2.imwrite('%s/%s.png' % (save_dir+'/positive_msle/', basename), p_map*255)\n",
    "    cv2.imwrite('%s/%s.png' % (save_dir+'/negative_msle/', basename), n_map*255)\n",
    "    \n",
    "#     cv2.imwrite('%s/%s_b.png' % (save_dir, basename), pred[0][:,:,0]*255)\n",
    "#     cv2.imwrite('%s/%s_p.png' % (save_dir, basename), p_map*255)\n",
    "#     cv2.imwrite('%s/%s_n.png' % (save_dir, basename), n_map*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4a084b2860>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000, 1000, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pred = cv2.imread(\"/home1/gzy/NucleiSegmentation/CoNSeP/Predicts_Hover/negative_4/test_4.png\", 0)\n",
    "ture = cv2.imread(\"/home1/gzy/NucleiSegmentation/CoNSeP/Test/Maps/negative/test_4.png\", 0)\n",
    "inst = sio.loadmat(\"/home1/gzy/NucleiSegmentation/CoNSeP/Test/Labels/test_4.mat\")['inst_map']\n",
    "\n",
    "import scipy.stats\n",
    "inst_list = list(np.unique(inst))[1:]\n",
    "for i in inst_list:\n",
    "    x_min, x_max = np.where(inst==i)[0].min(), np.where(inst==i)[0].max()\n",
    "    y_min, y_max = np.where(inst==i)[1].min(), np.where(inst==i)[1].max()\n",
    "    inst_temp = inst[x_min:x_max,y_min:y_max].copy()\n",
    "    inst_temp[inst_temp!=i] = 0\n",
    "    inst_temp[inst_temp==i] = 1\n",
    "    pred_temp = pred[x_min:x_max,y_min:y_max]*inst_temp/255\n",
    "    # pred_temp = (pred_temp-pred_temp.min())/(pred_temp.max()-pred_temp.min())\n",
    "    ture_temp = ture[x_min:x_max,y_min:y_max]*inst_temp/255\n",
    "    # ture_temp = (ture_temp-ture_temp.min())/(ture_temp.max()-ture_temp.min())\n",
    "    #plt.imshow(np.concatenate((ture_temp,pred_temp),axis=1))\n",
    "    img = np.concatenate((ture_temp,pred_temp),axis=1)*255\n",
    "    pred_temp = pred_temp.reshape(pred_temp.shape[0]*pred_temp.shape[1])\n",
    "    ture_temp = ture_temp.reshape(ture_temp.shape[0]*ture_temp.shape[1])\n",
    "    KL = scipy.stats.entropy(ture_temp, pred_temp) \n",
    "    cv2.imwrite('/home1/gzy/NucleiSegmentation/CoNSeP/Test/results/%4f.png' % KL, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(\"/home1/gzy/NucleiSegmentation/CoNSeP/Test/400x400_160x160_dg4_mask/test_1_046.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-hovernet] *",
   "language": "python",
   "name": "conda-env-.conda-hovernet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
